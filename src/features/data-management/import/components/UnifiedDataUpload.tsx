import { useState, useCallback } from "react";
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
import { Button } from "@/components/ui/button";
import { useToast } from "@/hooks/use-toast";
import { supabase } from "@/integrations/supabase/client";
import { Upload, FileSpreadsheet, Box, Wifi, Loader2, CheckCircle2, XCircle, AlertCircle } from "lucide-react";
import { Progress } from "@/components/ui/progress";
import { Badge } from "@/components/ui/badge";
import { Alert, AlertDescription } from "@/components/ui/alert";
import * as XLSX from "xlsx";

interface UnifiedDataUploadProps {
  storeId?: string;
  onUploadSuccess?: () => void;
}

interface UploadFile {
  file: File;
  id: string;
  type: 'csv' | 'excel' | '3d-model' | 'wifi' | 'json' | 'unknown';
  status: 'pending' | 'uploading' | 'processing' | 'mapping' | 'success' | 'error';
  progress: number;
  error?: string;
  mappingResult?: any;
}

export function UnifiedDataUpload({ storeId, onUploadSuccess }: UnifiedDataUploadProps) {
  const { toast } = useToast();
  const [files, setFiles] = useState<UploadFile[]>([]);
  const [isDragging, setIsDragging] = useState(false);

  // íŒŒì¼ íƒ€ì… ìë™ ê°ì§€
  const detectFileType = (file: File): UploadFile['type'] => {
    const ext = file.name.split('.').pop()?.toLowerCase();
    
    if (ext === 'csv') return 'csv';
    if (ext === 'xlsx' || ext === 'xls') return 'excel';
    if (ext === 'glb' || ext === 'gltf') return '3d-model';
    if (file.name.includes('wifi') || file.name.includes('tracking') || file.name.includes('sensor')) {
      return 'wifi';
    }
    if (ext === 'json') {
      if (file.name.includes('wifi')) return 'wifi';
      if (file.name.includes('metadata') || file.name.includes('3d')) return 'json';
      return 'json';
    }
    
    return 'unknown';
  };

  // íŒŒì¼ ì„ íƒ/ë“œë¡­ ì²˜ë¦¬
  const handleFiles = useCallback((newFiles: FileList | File[]) => {
    const fileArray = Array.from(newFiles);
    const uploadFiles: UploadFile[] = fileArray.map(file => {
      const fileName = file.name.toLowerCase();
      
      // íŒŒìƒ ë°ì´í„° íŒŒì¼ ê°ì§€ ë° ê²½ê³ 
      if (fileName.includes('dashboard_kpi') || fileName.includes('ai_recommendation')) {
        toast({
          title: 'âš ï¸ ìë™ ìƒì„± ë°ì´í„°',
          description: `${file.name}ëŠ” ë°±ì—”ë“œì—ì„œ ìë™ ìƒì„±ë˜ëŠ” íŒŒì¼ì…ë‹ˆë‹¤. ì›ì²œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ì§‘ê³„ë©ë‹ˆë‹¤.`,
          variant: 'destructive',
        });
      }
      
      return {
        file,
        id: Math.random().toString(36).substr(2, 9),
        type: detectFileType(file),
        status: 'pending' as const,
        progress: 0,
      };
    });

    setFiles(prev => [...prev, ...uploadFiles]);
  }, [toast]);

  const handleDragOver = (e: React.DragEvent) => {
    e.preventDefault();
    setIsDragging(true);
  };

  const handleDragLeave = (e: React.DragEvent) => {
    e.preventDefault();
    setIsDragging(false);
  };

  const handleDrop = (e: React.DragEvent) => {
    e.preventDefault();
    setIsDragging(false);
    if (e.dataTransfer.files) {
      handleFiles(e.dataTransfer.files);
    }
  };

  const handleFileInput = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files) {
      handleFiles(e.target.files);
    }
  };

  // CSV/Excel/JSON íŒŒì‹±
  const parseDataFile = async (file: File): Promise<any[]> => {
    const ext = file.name.split('.').pop()?.toLowerCase();
    
    if (ext === 'csv') {
      const text = await file.text();
      const lines = text.trim().split('\n');
      if (lines.length < 2) return [];
      
      const headers = lines[0].split(',').map(h => h.trim().replace(/^"|"$/g, ''));
      return lines.slice(1).map(line => {
        const values = line.split(',').map(v => v.trim().replace(/^"|"$/g, ''));
        const row: any = {};
        headers.forEach((header, i) => {
          row[header] = values[i] || '';
        });
        return row;
      });
    } else if (ext === 'xlsx' || ext === 'xls') {
      const arrayBuffer = await file.arrayBuffer();
      const workbook = XLSX.read(arrayBuffer, { type: 'array' });
      const firstSheet = workbook.Sheets[workbook.SheetNames[0]];
      return XLSX.utils.sheet_to_json(firstSheet);
    } else if (ext === 'json') {
      const text = await file.text();
      const jsonData = JSON.parse(text);
      // JSONì´ ë°°ì—´ì´ë©´ ê·¸ëŒ€ë¡œ, ê°ì²´ë©´ ë°°ì—´ë¡œ ê°ì‹¸ê¸°
      return Array.isArray(jsonData) ? jsonData : [jsonData];
    }
    
    return [];
  };

  // ìë™ ë§¤í•‘ ì‹¤í–‰
  const runAutoMapping = async (uploadFile: UploadFile, rawData: any[], filePath?: string) => {
    if (rawData.length === 0) return null;

    try {
      const columns = Object.keys(rawData[0]);
      const dataSample = rawData.slice(0, 5);

      const { data: { user } } = await supabase.auth.getUser();
      if (!user) throw new Error('ì¸ì¦ë˜ì§€ ì•Šì€ ì‚¬ìš©ì');

      const { data: importRecord } = await supabase
        .from('user_data_imports')
        .insert({
          file_name: uploadFile.file.name,
          file_type: uploadFile.type,
          data_type: 'auto-detected',
          raw_data: rawData as any,
          row_count: rawData.length,
          store_id: storeId || null,
          user_id: user.id,
          file_path: filePath || null,
        })
        .select()
        .single();

      if (!importRecord) return null;

      const { data: mappingResult, error: mappingError } = await supabase.functions.invoke('auto-map-etl', {
        body: {
          import_id: importRecord.id,
          data_sample: dataSample,
          columns: columns,
        }
      });

      if (mappingError) throw mappingError;
      return { importId: importRecord.id, ...mappingResult };
    } catch (error) {
      console.error('Auto mapping error:', error);
      return null;
    }
  };

  // íŒŒì¼ëª… sanitize (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
  const sanitizeFileName = (fileName: string): string => {
    // í™•ì¥ì ë¶„ë¦¬
    const lastDot = fileName.lastIndexOf('.');
    const name = lastDot > 0 ? fileName.substring(0, lastDot) : fileName;
    const ext = lastDot > 0 ? fileName.substring(lastDot) : '';
    
    // ì•ˆì „í•œ ë¬¸ìë§Œ í—ˆìš© (ì˜ë¬¸, ìˆ«ì, ì–¸ë”ìŠ¤ì½”ì–´, í•˜ì´í”ˆ, ì )
    // í•œê¸€, ê³µë°±, ê´„í˜¸ ë“±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€í™˜
    const safeName = name
      .replace(/[^\w\-\.]/g, '_')  // íŠ¹ìˆ˜ë¬¸ìë¥¼ _ë¡œ ë³€í™˜
      .replace(/_{2,}/g, '_')       // ì—°ì†ëœ _ë¥¼ í•˜ë‚˜ë¡œ
      .replace(/^_+|_+$/g, '');     // ì•ë’¤ _ì œê±°
    
    return safeName + ext;
  };

  // ê°œë³„ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
  const uploadFile = async (uploadFile: UploadFile) => {
    if (!storeId) {
      updateFileStatus(uploadFile.id, 'error', 'Store IDê°€ í•„ìš”í•©ë‹ˆë‹¤');
      return;
    }

    try {
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) throw new Error('ì¸ì¦ë˜ì§€ ì•Šì€ ì‚¬ìš©ì');

      updateFileStatus(uploadFile.id, 'uploading', undefined, 10);

      // íŒŒì¼ëª… sanitize
      const safeFileName = sanitizeFileName(uploadFile.file.name);

      // íŒŒì¼ íƒ€ì…ë³„ ì—…ë¡œë“œ
      if (uploadFile.type === '3d-model') {
        // === ì™„ì „ ìë™í™” 3D ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ===
        const filePath = `${user.id}/${storeId}/${safeFileName}`;
        const { error: uploadError } = await supabase.storage
          .from('3d-models')
          .upload(filePath, uploadFile.file, { upsert: true });

        if (uploadError) throw uploadError;
        
        // ì—…ë¡œë“œëœ URL ê°€ì ¸ì˜¤ê¸°
        const { data: { publicUrl } } = supabase.storage
          .from('3d-models')
          .getPublicUrl(filePath);
        
        // Step 1: 3D ëª¨ë¸ AI ë¶„ì„ ë° ì—”í‹°í‹° íƒ€ì… ìë™ ìƒì„±
        updateFileStatus(uploadFile.id, 'processing', 'AI ë¶„ì„ ì¤‘...', 40);
        
        try {
          const { data: processResult, error: processError } = await supabase.functions.invoke('auto-process-3d-models', {
            body: {
              files: [{
                fileName: safeFileName,
                publicUrl: publicUrl
              }],
              storeId: storeId
            }
          });
          
          if (processError) throw processError;
          
          if (processResult?.success && processResult.results?.[0]) {
            const result = processResult.results[0];
            
            // Step 2: user_data_importsì— ê¸°ë¡ ì¶”ê°€
            updateFileStatus(uploadFile.id, 'processing', 'ë°ì´í„° ê¸°ë¡ ì¤‘...', 60);
            await supabase.from('user_data_imports').insert({
              user_id: user.id,
              store_id: storeId,
              file_name: safeFileName,
              file_type: '3d_model',
              data_type: '3d_model',
              file_path: filePath,
              row_count: 1,
              raw_data: {
                entityType: result?.entityType,
                instanceLabel: result?.instanceLabel,
                position: result?.position,
                publicUrl: publicUrl
              }
            });
            
            // Step 3: ê¸°ì¡´ ì—”í‹°í‹°ì— 3D ëª¨ë¸ ìë™ ë§¤í•‘
            updateFileStatus(uploadFile.id, 'processing', 'ê¸°ì¡´ ì—”í‹°í‹°ì— ë§¤í•‘ ì¤‘...', 75);
            
            // AIê°€ ìƒì„±í•œ ì—”í‹°í‹° íƒ€ì… ì´ë¦„ìœ¼ë¡œ ê¸°ì¡´ ì—”í‹°í‹° ì°¾ê¸°
            const { data: entityType } = await supabase
              .from('ontology_entity_types')
              .select('id')
              .eq('user_id', user.id)
              .eq('name', result.entityType)
              .single();

            let mappedCount = 0;
            if (entityType) {
              // í•´ë‹¹ íƒ€ì…ì˜ ì—”í‹°í‹° ì¤‘ 3D ëª¨ë¸ì´ ì—†ëŠ” ì—”í‹°í‹° ì°¾ê¸° (ìµœëŒ€ 10ê°œ)
              const { data: entitiesToMap } = await supabase
                .from('graph_entities')
                .select('id')
                .eq('user_id', user.id)
                .eq('store_id', storeId)
                .eq('entity_type_id', entityType.id)
                .is('model_3d_position', null)
                .limit(10);

              if (entitiesToMap && entitiesToMap.length > 0) {
                console.log(`ğŸ”— Auto-mapping 3D model to ${entitiesToMap.length} entities...`);
                
                // ê·¸ë¦¬ë“œ í˜•íƒœë¡œ ìë™ ë°°ì¹˜
                const updates = entitiesToMap.map((entity, idx) => 
                  supabase
                    .from('graph_entities')
                    .update({
                      model_3d_position: { x: idx * 2, y: 0, z: 0 },
                      model_3d_scale: { x: 1, y: 1, z: 1 },
                      model_3d_rotation: { x: 0, y: 0, z: 0 }
                    })
                    .eq('id', entity.id)
                );
                
                await Promise.all(updates);
                mappedCount = entitiesToMap.length;
                console.log(`âœ… 3D models auto-mapped to ${mappedCount} entities`);
              }
            }
            
            updateFileStatus(uploadFile.id, 'success', undefined, 100, {
              autoMapped: true,
              entityType: result?.entityType || 'ìë™ ìƒì„±ë¨',
              instanceLabel: result?.instanceLabel,
              position: result?.position,
              entitiesMapped: mappedCount,
              linkedToOntology: true
            });
          } else {
            throw new Error(processResult?.error || 'ìë™ ì²˜ë¦¬ ì‹¤íŒ¨');
          }
        } catch (err: any) {
          console.error('âŒ 3D model processing failed:', err);
          updateFileStatus(uploadFile.id, 'error', err.message || 'ìë™ ì²˜ë¦¬ ì‹¤íŒ¨');
        }
        
      } else if (uploadFile.type === 'csv' || uploadFile.type === 'excel') {
        // === ì™„ì „ ìë™í™” CSV/Excel íŒŒì´í”„ë¼ì¸ ===
        updateFileStatus(uploadFile.id, 'processing', 'íŒŒì¼ ì—…ë¡œë“œ ì¤‘...', 15);
        
        const filePath = `${user.id}/${storeId}/${safeFileName}`;
        const { error: uploadError } = await supabase.storage
          .from('store-data')
          .upload(filePath, uploadFile.file, { upsert: true });

        if (uploadError) throw uploadError;
        
        // Step 1: ë°ì´í„° íŒŒì‹±
        updateFileStatus(uploadFile.id, 'processing', 'ë°ì´í„° íŒŒì‹± ì¤‘...', 25);
        const rawData = await parseDataFile(uploadFile.file);
        
        // Step 2: user_data_importsì— ë ˆì½”ë“œ ìƒì„±
        updateFileStatus(uploadFile.id, 'processing', 'ë°ì´í„° ê²€ì¦ ì¤€ë¹„ ì¤‘...', 35);
        const { data: importRecord, error: importError } = await supabase
          .from('user_data_imports')
          .insert({
            file_name: safeFileName,
            file_type: uploadFile.type,
            data_type: 'auto-detected',
            raw_data: rawData as any,
            row_count: rawData.length,
            store_id: storeId || null,
            user_id: user.id,
            file_path: filePath,
          })
          .select()
          .single();

        if (importError || !importRecord) {
          throw new Error(`Import record creation failed: ${importError?.message}`);
        }

        // Step 3: ë°ì´í„° ìë™ ìˆ˜ì • (ê²€ì¦ ë° ì •ë¦¬)
        console.log('ğŸ”§ Step 3: Auto-fixing data...');
        updateFileStatus(uploadFile.id, 'processing', 'ë°ì´í„° ê²€ì¦ ë° ìë™ ìˆ˜ì • ì¤‘...', 45);
        
        try {
          const { data: fixResult, error: fixError } = await supabase.functions.invoke('auto-fix-data', {
            body: {
              importId: importRecord.id,
              options: {
                removeDuplicates: true,
                fillEmptyValues: true,
                convertTypes: true,
                useAI: false,
              },
            },
          });

          if (fixError) {
            console.warn('âš ï¸ Auto-fix warning:', fixError);
          } else {
            console.log('âœ… Data auto-fixed:', fixResult);
          }
        } catch (fixErr) {
          console.warn('âš ï¸ Auto-fix failed (continuing):', fixErr);
        }

        // Step 4: ìë™ ë§¤í•‘
        updateFileStatus(uploadFile.id, 'mapping', 'ìŠ¤í‚¤ë§ˆ ìë™ ë§¤í•‘ ì¤‘...', 55);
        const columns = rawData.length > 0 ? Object.keys(rawData[0]) : [];
        const dataSample = rawData.slice(0, 5);

        const { data: mappingResult, error: mappingError } = await supabase.functions.invoke('auto-map-etl', {
          body: {
            import_id: importRecord.id,
            data_sample: dataSample,
            columns: columns,
          }
        });

        if (mappingError || !mappingResult) {
          throw new Error(`Auto-mapping failed: ${mappingError?.message || 'No mapping result'}`);
        }

        console.log('âœ… Auto-mapping completed:', mappingResult);
        
        // Step 5: ETL ì‹¤í–‰ (ì˜¨í†¨ë¡œì§€ ë³€í™˜)
        if (mappingResult && storeId) {
          try {
            updateFileStatus(uploadFile.id, 'processing', 'ì˜¨í†¨ë¡œì§€ ì—”í‹°í‹° ìƒì„± ì¤‘...', 70);
            
            const { data: etlResult, error: etlError } = await supabase.functions.invoke('schema-etl', {
              body: {
                user_id: user.id,
                store_id: storeId,
                import_id: importRecord.id,
                entity_mappings: mappingResult.entity_mappings || [],
                relation_mappings: mappingResult.relation_mappings || []
              }
            });

            if (etlError) throw etlError;
            
            updateFileStatus(uploadFile.id, 'processing', 'KPI ì§‘ê³„ ë° AI ë¶„ì„ ì¤‘...', 85);

            // Step 4: ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… (KPI ì§‘ê³„ + AI ì¶”ì²œ)
            // ë¹„ë™ê¸°ë¡œ ì‹¤í–‰í•˜ì—¬ ì‚¬ìš©ì ê²½í—˜ ê°œì„ 
            (async () => {
              try {
                console.log('ğŸ“Š Step 4: KPI aggregation for all dates...');
                const { data: aggregateResult, error: aggregateError } = await supabase.functions.invoke('aggregate-all-kpis', {
                  body: { 
                    store_id: storeId,
                    user_id: user.id
                  },
                });
                
                if (aggregateError) {
                  console.warn('âš ï¸ KPI aggregation warning:', aggregateError);
                } else {
                  console.log('âœ… Dashboard KPIs aggregated:', aggregateResult);
                }
                
                // Step 5: AI ì¶”ì²œ ìë™ ìƒì„±
                console.log('ğŸ¤– Step 5: Generating AI recommendations...');
                const { error: aiError } = await supabase.functions.invoke('generate-ai-recommendations', {
                  body: { store_id: storeId },
                });
                
                if (aiError) {
                  console.warn('âš ï¸ AI recommendations warning:', aiError);
                } else {
                  console.log('âœ… AI recommendations generated');
                }
              } catch (bgError) {
                console.warn('âš ï¸ Background processing failed (non-critical):', bgError);
              }
            })();
            
            updateFileStatus(uploadFile.id, 'success', 'ëª¨ë“  ìë™í™” í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!', 100, {
              ...mappingResult,
              autoMapped: true,
              autoFixed: true,
              entitiesCreated: etlResult?.entities_created || 0,
              relationsCreated: etlResult?.relations_created || 0,
              kpiAggregated: true,
              aiGenerated: true,
              filePath
            });
            
            console.log('ğŸ‰ CSV ì™„ì „ ìë™í™” íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!');
            toast({ title: `${safeFileName} ì—…ë¡œë“œ ë° ë¶„ì„ ì™„ë£Œ!` });
          } catch (etlError) {
            console.error('âŒ Auto ETL error:', etlError);
            
            // ì¬ì‹œë„ ë¡œì§ (1íšŒ) - íŒŒë¼ë¯¸í„° ìˆ˜ì •
            console.log('ğŸ”„ Retrying ETL process...');
            try {
              const { data: retryResult, error: retryError } = await supabase.functions.invoke('schema-etl', {
                body: {
                  user_id: user.id,
                  store_id: storeId,
                  import_id: importRecord.id,
                  entity_mappings: mappingResult.entity_mappings || [],
                  relation_mappings: mappingResult.relation_mappings || []
                },
              });
              
              if (!retryError && retryResult) {
                console.log('âœ… ETL succeeded on retry');
                
                // ì¬ì‹œë„ ì„±ê³µ ì‹œì—ë„ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤í–‰
                (async () => {
                  try {
                    await supabase.functions.invoke('aggregate-all-kpis', {
                      body: { store_id: storeId, user_id: user.id },
                    });
                    await supabase.functions.invoke('generate-ai-recommendations', {
                      body: { store_id: storeId },
                    });
                  } catch (bgErr) {
                    console.warn('âš ï¸ Background tasks failed (non-critical):', bgErr);
                  }
                })();
                
                updateFileStatus(uploadFile.id, 'success', 'ì¬ì‹œë„ ì„±ê³µ!', 100, {
                  ...mappingResult,
                  autoMapped: true,
                  autoFixed: true,
                  retriedETL: true,
                  entitiesCreated: retryResult?.entities_created || 0,
                  kpiAggregated: true,
                  aiGenerated: true,
                  filePath
                });
                toast({ title: `${safeFileName} ì¬ì‹œë„ ì„±ê³µ!` });
              } else {
                throw retryError || new Error('Retry failed');
              }
            } catch (retryErr) {
              console.error('âŒ ETL retry also failed:', retryErr);
              updateFileStatus(uploadFile.id, 'error', `ETL ì‹¤íŒ¨: ${(etlError as Error).message}`);
              toast({ title: `${safeFileName} ë³€í™˜ ì‹¤íŒ¨`, description: 'ìˆ˜ë™ í™•ì¸ í•„ìš”', variant: 'destructive' });
            }
          }
        } else {
          console.log('âš ï¸ No mapping result, skipping ETL');
          updateFileStatus(uploadFile.id, 'success', 'ì—…ë¡œë“œ ì™„ë£Œ (ë§¤í•‘ ì—†ìŒ)', 100, { filePath });
        }
        
      } else if (uploadFile.type === 'wifi') {
        // WiFi ë°ì´í„°ëŠ” store-data ë²„í‚·ì— ì—…ë¡œë“œ
        const filePath = `${user.id}/${storeId}/${safeFileName}`;
        const { error: uploadError } = await supabase.storage
          .from('store-data')
          .upload(filePath, uploadFile.file, { upsert: true });

        if (uploadError) throw uploadError;
        
        updateFileStatus(uploadFile.id, 'processing', undefined, 50);
        
        // WiFi ë°ì´í„° ìë™ ì²˜ë¦¬
        const { data: processResult, error: processError } = await supabase.functions.invoke('process-wifi-data', {
          body: {
            filePath,
            storeId
          }
        });

        if (processError) throw processError;

        if (processResult?.success) {
          updateFileStatus(uploadFile.id, 'success', undefined, 100, {
            processedCount: processResult.processedCount,
            metadataGenerated: !!processResult.metadata
          });
        } else {
          throw new Error(processResult?.error || 'WiFi ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨');
        }
        
      } else if (uploadFile.type === 'json') {
        // JSON ë©”íƒ€ë°ì´í„°ëŠ” store-data ë²„í‚·ì— ì—…ë¡œë“œ
        updateFileStatus(uploadFile.id, 'processing', 'íŒŒì¼ ì—…ë¡œë“œ ì¤‘...', 20);
        
        const filePath = `${user.id}/${storeId}/metadata/${safeFileName}`;
        const { error: uploadError } = await supabase.storage
          .from('store-data')
          .upload(filePath, uploadFile.file, { upsert: true });

        if (uploadError) throw uploadError;
        
        updateFileStatus(uploadFile.id, 'processing', 'ë°ì´í„° íŒŒì‹± ì¤‘...', 50);
        const rawData = await parseDataFile(uploadFile.file);
        
        // user_data_importsì— ê¸°ë¡
        const { data: importData, error: importError } = await supabase
          .from('user_data_imports')
          .insert({
            user_id: user.id,
            store_id: storeId,
            file_name: safeFileName,
            file_type: 'json',
            data_type: 'metadata',
            file_path: filePath,
            row_count: rawData.length,
            raw_data: rawData
          })
          .select()
          .single();

        if (importError) throw importError;
        
        updateFileStatus(uploadFile.id, 'success', undefined, 100, {
          importId: importData.id,
          recordCount: rawData.length,
          filePath
        });
        
      } else {
        throw new Error('ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…');
      }

      toast({
        title: "ì—…ë¡œë“œ ì™„ë£Œ",
        description: `${uploadFile.file.name}ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤`,
      });

    } catch (error: any) {
      updateFileStatus(uploadFile.id, 'error', error.message);
      toast({
        title: "ì—…ë¡œë“œ ì‹¤íŒ¨",
        description: error.message,
        variant: "destructive",
      });
    }
  };

  const updateFileStatus = (
    id: string, 
    status: UploadFile['status'], 
    error?: string, 
    progress?: number,
    mappingResult?: any
  ) => {
    setFiles(prev => prev.map(f => 
      f.id === id 
        ? { ...f, status, error, progress: progress ?? f.progress, mappingResult } 
        : f
    ));
  };

  const uploadAllFiles = async () => {
    const pendingFiles = files.filter(f => f.status === 'pending');
    for (const file of pendingFiles) {
      await uploadFile(file);
    }
    onUploadSuccess?.();
  };

  const removeFile = (id: string) => {
    setFiles(prev => prev.filter(f => f.id !== id));
  };

  const clearCompleted = () => {
    setFiles(prev => prev.filter(f => f.status !== 'success'));
  };

  const getFileTypeIcon = (type: UploadFile['type']) => {
    switch (type) {
      case 'csv':
      case 'excel':
        return <FileSpreadsheet className="w-5 h-5" />;
      case '3d-model':
        return <Box className="w-5 h-5" />;
      case 'wifi':
        return <Wifi className="w-5 h-5" />;
      case 'json':
        return <FileSpreadsheet className="w-5 h-5" />;
      default:
        return <AlertCircle className="w-5 h-5" />;
    }
  };

  const getFileTypeBadge = (type: UploadFile['type']) => {
    const variants: Record<UploadFile['type'], string> = {
      'csv': 'bg-blue-500/10 text-blue-500 border-blue-500/20',
      'excel': 'bg-green-500/10 text-green-500 border-green-500/20',
      '3d-model': 'bg-purple-500/10 text-purple-500 border-purple-500/20',
      'wifi': 'bg-orange-500/10 text-orange-500 border-orange-500/20',
      'json': 'bg-cyan-500/10 text-cyan-500 border-cyan-500/20',
      'unknown': 'bg-gray-500/10 text-gray-500 border-gray-500/20',
    };

    const labels: Record<UploadFile['type'], string> = {
      'csv': 'CSV',
      'excel': 'Excel',
      '3d-model': '3D ëª¨ë¸',
      'wifi': 'WiFi',
      'json': 'JSON',
      'unknown': 'ì•Œ ìˆ˜ ì—†ìŒ',
    };

    return (
      <Badge variant="outline" className={variants[type]}>
        {labels[type]}
      </Badge>
    );
  };

  const getStatusIcon = (status: UploadFile['status']) => {
    switch (status) {
      case 'success':
        return <CheckCircle2 className="w-5 h-5 text-green-500" />;
      case 'error':
        return <XCircle className="w-5 h-5 text-red-500" />;
      case 'uploading':
      case 'processing':
      case 'mapping':
        return <Loader2 className="w-5 h-5 animate-spin text-primary" />;
      default:
        return null;
    }
  };

  const getStatusText = (uploadFile: UploadFile) => {
    if (uploadFile.status === 'success' && uploadFile.mappingResult) {
      if (uploadFile.type === '3d-model') {
        if (uploadFile.mappingResult.autoMapped) {
          const instanceInfo = uploadFile.mappingResult.instanceLabel 
            ? ` â†’ ${uploadFile.mappingResult.instanceLabel}` 
            : '';
          return `ìë™ ë§¤í•‘ ì™„ë£Œ: ${uploadFile.mappingResult.entityType}${instanceInfo}`;
        } else {
          return uploadFile.mappingResult.message || 'ì—…ë¡œë“œ ì™„ë£Œ';
        }
      } else if (uploadFile.mappingResult.importId) {
        return `ìë™ ë§¤í•‘ ì™„ë£Œ (Import ID: ${uploadFile.mappingResult.importId})`;
      }
    }
    
    const statusMap = {
      pending: 'ëŒ€ê¸° ì¤‘',
      uploading: 'ì—…ë¡œë“œ ì¤‘...',
      processing: 'ì²˜ë¦¬ ì¤‘...',
      mapping: 'ìë™ ë§¤í•‘ ì¤‘...',
      success: 'ì™„ë£Œ',
      error: uploadFile.error || 'ì‹¤íŒ¨'
    };
    return statusMap[uploadFile.status];
  };

  return (
    <Card>
      <CardHeader>
        <CardTitle>í†µí•© ë°ì´í„° ì—…ë¡œë“œ</CardTitle>
        <CardDescription>
          ëª¨ë“  íƒ€ì…ì˜ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì—…ë¡œë“œí•˜ê³  ìë™ìœ¼ë¡œ ì¸ì‹/ë§¤í•‘í•©ë‹ˆë‹¤
        </CardDescription>
      </CardHeader>
      <CardContent className="space-y-6">
        {!storeId && (
          <Alert>
            <AlertCircle className="h-4 w-4" />
            <AlertDescription>
              ë§¤ì¥ì„ ë¨¼ì € ì„ íƒí•´ì£¼ì„¸ìš”
            </AlertDescription>
          </Alert>
        )}

        {/* ë“œë˜ê·¸ ì•¤ ë“œë¡­ ì˜ì—­ */}
        <div
          onDragOver={handleDragOver}
          onDragLeave={handleDragLeave}
          onDrop={handleDrop}
          className={`border-2 border-dashed rounded-lg p-12 text-center transition-colors ${
            isDragging 
              ? 'border-primary bg-primary/5' 
              : 'border-muted-foreground/25 hover:border-primary/50'
          }`}
        >
          <Upload className="w-12 h-12 mx-auto mb-4 text-muted-foreground" />
          <p className="text-lg font-medium mb-2">
            íŒŒì¼ì„ ì—¬ê¸°ì— ë“œë¡­í•˜ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì„ íƒ
          </p>
          <p className="text-sm text-muted-foreground mb-4">
            CSV, Excel, 3D ëª¨ë¸(.glb/.gltf), WiFi ë°ì´í„° ì§€ì›
          </p>
          <input
            type="file"
            id="file-upload"
            multiple
            accept=".csv,.xlsx,.xls,.glb,.gltf,.json"
            onChange={handleFileInput}
            className="hidden"
            disabled={!storeId}
          />
          <Button asChild disabled={!storeId}>
            <label htmlFor="file-upload" className="cursor-pointer">
              íŒŒì¼ ì„ íƒ
            </label>
          </Button>
        </div>

        {/* ì—…ë¡œë“œ íŒŒì¼ ëª©ë¡ */}
        {files.length > 0 && (
          <div className="space-y-4">
            <div className="flex items-center justify-between">
              <h3 className="text-lg font-semibold">ì—…ë¡œë“œ ëŒ€ê¸° ì¤‘ì¸ íŒŒì¼ ({files.length})</h3>
              <div className="flex gap-2">
                <Button
                  variant="outline"
                  size="sm"
                  onClick={clearCompleted}
                  disabled={!files.some(f => f.status === 'success')}
                >
                  ì™„ë£Œëœ í•­ëª© ì œê±°
                </Button>
                <Button
                  onClick={uploadAllFiles}
                  disabled={!files.some(f => f.status === 'pending')}
                >
                  <Upload className="w-4 h-4 mr-2" />
                  ëª¨ë‘ ì—…ë¡œë“œ
                </Button>
              </div>
            </div>

            <div className="space-y-2">
              {files.map(file => (
                <div
                  key={file.id}
                  className="border rounded-lg p-4 space-y-3"
                >
                  <div className="flex items-start justify-between">
                    <div className="flex items-center gap-3 flex-1">
                      {getFileTypeIcon(file.type)}
                      <div className="flex-1 min-w-0">
                        <div className="flex items-center gap-2 mb-1">
                          <p className="font-medium truncate">{file.file.name}</p>
                          {getFileTypeBadge(file.type)}
                        </div>
                        <p className="text-sm text-muted-foreground">
                          {(file.file.size / 1024).toFixed(1)} KB
                        </p>
                      </div>
                    </div>
                    <div className="flex items-center gap-2">
                      {getStatusIcon(file.status)}
                      {file.status === 'pending' && (
                        <Button
                          variant="ghost"
                          size="sm"
                          onClick={() => removeFile(file.id)}
                        >
                          <XCircle className="w-4 h-4" />
                        </Button>
                      )}
                    </div>
                  </div>

                  {file.status !== 'pending' && file.status !== 'success' && (
                    <div className="space-y-1">
                      <div className="flex items-center justify-between text-sm">
                        <span className="text-muted-foreground">
                          {getStatusText(file)}
                        </span>
                        <span className="font-medium">{file.progress}%</span>
                      </div>
                      <Progress value={file.progress} />
                    </div>
                  )}

                  {file.status === 'success' && (
                    <div className="text-sm text-green-600 dark:text-green-400">
                      {getStatusText(file)}
                    </div>
                  )}

                  {file.error && (
                    <Alert variant="destructive">
                      <AlertDescription>{file.error}</AlertDescription>
                    </Alert>
                  )}

                  {file.mappingResult && file.mappingResult.entity_mappings && (
                    <Alert>
                      <CheckCircle2 className="h-4 w-4" />
                      <AlertDescription>
                        ìë™ ë§¤í•‘ ì™„ë£Œ: {file.mappingResult.entity_mappings?.length || 0}ê°œ ì—”í‹°í‹°, {' '}
                        {file.mappingResult.relation_mappings?.length || 0}ê°œ ê´€ê³„
                      </AlertDescription>
                    </Alert>
                  )}
                </div>
              ))}
            </div>
          </div>
        )}
      </CardContent>
    </Card>
  );
}
